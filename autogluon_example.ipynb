{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fake Real Estate Advertisement Detection with AutoGluon**"
      ],
      "metadata": {
        "id": "rVtqGijCEKyq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Install AutoGluon**"
      ],
      "metadata": {
        "id": "v0ykdXE9DmBI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMGp7piHtAlL"
      },
      "outputs": [],
      "source": [
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Load and inspect the training data**\n",
        "\n",
        "We create a **TabularDataset** object from a given URL link and store this object in the **train_data** variable. This variable now contains our training dataset."
      ],
      "metadata": {
        "id": "oW86wlEODvh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset\n",
        "\n",
        "train_data_url = 'https://nvcuong.github.io/files/autogluon_train.csv'\n",
        "train_data = TabularDataset(train_data_url)"
      ],
      "metadata": {
        "id": "PHB5NtSzvehs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can look at the first 5 rows in the data."
      ],
      "metadata": {
        "id": "EtpsrR7pEB3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "gp3Xah5U1u6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look at the size of the data. The dataset contains 23268 rows and 20 columns."
      ],
      "metadata": {
        "id": "ETEYsIBSKAI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.shape)"
      ],
      "metadata": {
        "id": "XSP5C1hI1oMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we list all the column names to see which features we have.\n",
        "\n",
        "Note that the column **label** (last column) is what we need to predict (1 = fake, 0 = real) from the other columns."
      ],
      "metadata": {
        "id": "QdAO5Hr6Fhzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.columns)"
      ],
      "metadata": {
        "id": "uwtxkcgwyY0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Train the predictor**\n",
        "\n",
        "We can train a predictor using the **TabularPredictor** module. We need to specify the label column that we need to predict, and then call **fit(...)** with the training data.\n",
        "\n",
        "Here we set the time limit to 300 seconds (5 minutes) for demo purposes. Removing this limit will allow longer training time with potentially better result."
      ],
      "metadata": {
        "id": "ntdlQmMfKVHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "predictor = TabularPredictor(label='label').fit(train_data, time_limit=300)"
      ],
      "metadata": {
        "id": "YheesxbwzSXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Evaluate the predictor on test data**\n",
        "\n",
        "First, we load the test data like the way we loaded the training data before."
      ],
      "metadata": {
        "id": "JKonhhPwWt0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_url = 'https://nvcuong.github.io/files/autogluon_test.csv'\n",
        "\n",
        "test_data = TabularDataset(test_data_url)"
      ],
      "metadata": {
        "id": "RylGPd3AzaAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also look at the first 5 rows of the test data."
      ],
      "metadata": {
        "id": "UCMD3M-qXAi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "id": "iVw0sbmE14dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also check the size of the test data. This dataset contain 5817 rows with the same 20 columns."
      ],
      "metadata": {
        "id": "B7X1Nuv0GThf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data.shape)"
      ],
      "metadata": {
        "id": "mEhv5SPk16aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call the **evaluate(...)** function of the predictor to test and compute all the metrics.\n",
        "\n",
        "The results show that the accuracy of the model is around 94%."
      ],
      "metadata": {
        "id": "eRnEnlCZXRuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.evaluate(test_data)"
      ],
      "metadata": {
        "id": "Z1Cb0zfy2CGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can look at all the components of the predictor and their performance."
      ],
      "metadata": {
        "id": "HXUNLA9tXipO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard(test_data)"
      ],
      "metadata": {
        "id": "UHQcfp8V2NPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. Interpret the model**\n",
        "\n",
        "Finally, we can compute and look at the feature importance.\n",
        "\n",
        "Here we only use 1000 random rows of the test data for faster computation."
      ],
      "metadata": {
        "id": "XvAY_SEFXoM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.feature_importance(test_data, subsample_size=1000)"
      ],
      "metadata": {
        "id": "DSWqN-ds2SkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}